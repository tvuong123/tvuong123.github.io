---
layout: page
title: Publications (IN PROGRESS)
---

**A MODULATION-DOMAIN LOSS FOR NEURAL-NETWORK-BASED REAL-TIME SPEECH ENHANCEMENT**
<img src="/assets/img/stme-flow.png" width="600" height="400">

[1] **T. Vuong**, Y. Xia, R.M. Stern, "A Modulation-Domain Loss for Neural-Network-based Real-time Speech Enhancement," *Accepted IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)*, May 2021, Toronto, Canada 

[paper][arXiv][code][presentation][BibTeX]


**LEARNABLE SPECTRO-TEMPORAL RECEPTIVE FIELDS FOR ROBUST VOICE TYPE DISCRIMINATION**

<img src="/assets/img/STRFNet.png" width="600" height="400">
[2] **T. Vuong**, Y. Xia, R.M. Stern, "Learnable Spectro-temporal Receptive Fields for Robust Voice Type Discrimination," *INTERSPEECH*, October 2020, Shanghai, China

[[paper](https://www.isca-speech.org/archive/Interspeech_2020/pdfs/1878.pdf)][[arXiv](https://arxiv.org/abs/2010.09151)][[code](https://github.com/raymondxyy/strfnet-IS2020)][presentation][[BibTeX](citations/learnable_citation.bib)]

**Exploring the Best Loss Function for DNN-Based Low-latency Speech Enhancement with Temporal Convolutional Networks**
<img src="/assets/img/nc_layers.png" width="600" height="400">

**4th Place on the non-real-time track on the Interspeech 2020 Deep Noise Surpression Challenge**\
[3] Y. Koyama, **T. Vuong**, S. Uhlich, and B. Raj, “Exploring the best loss function for DNN-based lowlatency speech enhancement with temporal convolutional networks,” arXiv preprint arXiv:2005.11611, 2020.

[[arXiv](https://arxiv.org/abs/2005.11611)][BibTeX][[challenge results (Sony and CMU team)](https://www.microsoft.com/en-us/research/academic-program/deep-noise-suppression-challenge-interspeech-2020/#!results)]


